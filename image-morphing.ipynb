{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Morphing\n",
    "### Load modules and set parameters\n",
    "Number of epochs should be much higher to give better results, but it is lowered due to long morphing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import cv2\n",
    "import argparse\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "ORIG_WIDTH = 0\n",
    "ORIG_HEIGHT = 0\n",
    "TRAIN_EPOCHS = 50\n",
    "\n",
    "im_sz = 1024\n",
    "mp_sz = 96\n",
    "\n",
    "warp_scale = 0.05\n",
    "mult_scale = 0.4\n",
    "add_scale = 0.4\n",
    "add_first = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def warp(origins, targets, preds_org, preds_trg):\n",
    "    if add_first:\n",
    "        res_targets = tfa.image.dense_image_warp((origins + preds_org[:,:,:,3:6] * 2 * add_scale) * tf.maximum(0.1, 1 + preds_org[:,:,:,0:3] * mult_scale) , preds_org[:,:,:,6:8] * im_sz * warp_scale )\n",
    "        res_origins = tfa.image.dense_image_warp((targets + preds_trg[:,:,:,3:6] * 2 * add_scale) * tf.maximum(0.1, 1 + preds_trg[:,:,:,0:3] * mult_scale) , preds_trg[:,:,:,6:8] * im_sz * warp_scale )\n",
    "    else:\n",
    "        res_targets = tfa.image.dense_image_warp(origins * tf.maximum(0.1, 1 + preds_org[:,:,:,0:3] * mult_scale) + preds_org[:,:,:,3:6] * 2 * add_scale, preds_org[:,:,:,6:8] * im_sz * warp_scale )\n",
    "        res_origins = tfa.image.dense_image_warp(targets * tf.maximum(0.1, 1 + preds_trg[:,:,:,0:3] * mult_scale) + preds_trg[:,:,:,3:6] * 2 * add_scale, preds_trg[:,:,:,6:8] * im_sz * warp_scale )\n",
    "\n",
    "    return res_targets, res_origins\n",
    "\n",
    "def create_grid(scale):\n",
    "    grid = np.mgrid[0:scale,0:scale] / (scale - 1) * 2 -1\n",
    "    grid = np.swapaxes(grid, 0, 2)\n",
    "    grid = np.expand_dims(grid, axis=0)\n",
    "    return grid\n",
    "\n",
    "def produce_warp_maps(origins, targets):\n",
    "    class MyModel(tf.keras.Model):\n",
    "        def __init__(self):\n",
    "            super(MyModel, self).__init__()\n",
    "            self.conv1 = tf.keras.layers.Conv2D(64, (5, 5))\n",
    "            self.act1 = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
    "            self.conv2 = tf.keras.layers.Conv2D(64, (5, 5))\n",
    "            self.act2 = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
    "            self.convo = tf.keras.layers.Conv2D((3 + 3 + 2) * 2, (5, 5))\n",
    "\n",
    "        def call(self, maps):\n",
    "            x = tf.image.resize(maps, [mp_sz, mp_sz])\n",
    "            x = self.conv1(x)\n",
    "            x = self.act1(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.act2(x)\n",
    "            x = self.convo(x)\n",
    "            return x\n",
    "\n",
    "\n",
    "    model = MyModel()\n",
    "\n",
    "    loss_object = tf.keras.losses.MeanSquaredError()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "\n",
    "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(maps, origins, targets):\n",
    "      with tf.GradientTape() as tape:\n",
    "        preds = model(maps)\n",
    "        preds = tf.image.resize(preds, [im_sz, im_sz])\n",
    "\n",
    "        #a = tf.random.uniform([maps.shape[0]])\n",
    "        #res_targets, res_origins = warp(origins, targets, preds[...,:8] * a, preds[...,8:] * (1 - a))\n",
    "        res_targets_, res_origins_ = warp(origins, targets, preds[...,:8], preds[...,8:])\n",
    "\n",
    "        # warp maps consistency checker\n",
    "        res_map = tfa.image.dense_image_warp(maps, preds[:,:,:,6:8] * im_sz * warp_scale )\n",
    "        res_map = tfa.image.dense_image_warp(res_map, preds[:,:,:,14:16] * im_sz * warp_scale )\n",
    "\n",
    "        loss = loss_object(maps, res_map) * 1 + loss_object(res_targets_, targets) * 0.3 + loss_object(res_origins_, origins) * 0.3\n",
    "\n",
    "      gradients = tape.gradient(loss, model.trainable_variables)\n",
    "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "      train_loss(loss)\n",
    "\n",
    "    maps = create_grid(im_sz)\n",
    "    maps = np.concatenate((maps, origins * 0.1, targets * 0.1), axis=-1).astype(np.float32)\n",
    "\n",
    "    epoch = 0\n",
    "    template = 'Epoch {}, Loss: {}'\n",
    "\n",
    "    t = tqdm(range(TRAIN_EPOCHS), desc=template.format(epoch, train_loss.result()))\n",
    "\n",
    "    for i in t:\n",
    "        epoch = i + 1\n",
    "\n",
    "        t.set_description(template.format(epoch, train_loss.result()))\n",
    "        t.refresh()\n",
    "\n",
    "        train_step(maps, origins, targets)\n",
    "\n",
    "        if (epoch < 100 and epoch % 10 == 0) or\\\n",
    "           (epoch < 1000 and epoch % 100 == 0) or\\\n",
    "           (epoch % 1000 == 0):\n",
    "            preds = model(maps, training=False)[:1]\n",
    "            preds = tf.image.resize(preds, [im_sz, im_sz])\n",
    "\n",
    "    return preds\n",
    "\n",
    "def generate_frames(origins, targets, preds, steps=100):\n",
    "    # apply maps\n",
    "    org_strength = tf.reshape(tf.range(steps, dtype=tf.float32), [steps, 1, 1, 1]) / (steps - 1)\n",
    "    trg_strength = tf.reverse(org_strength, axis = [0])\n",
    "\n",
    "    frames = []\n",
    "    for i in tqdm(range(steps)):\n",
    "        preds_org = preds * org_strength[i]\n",
    "        preds_trg = preds * trg_strength[i]\n",
    "\n",
    "        res_targets, res_origins = warp(origins, targets, preds_org[...,:8], preds_trg[...,8:])\n",
    "        res_targets = tf.clip_by_value(res_targets, -1, 1)\n",
    "        res_origins = tf.clip_by_value(res_origins, -1, 1)\n",
    "\n",
    "        results = res_targets * trg_strength[i] + res_origins * org_strength[i]\n",
    "        res_numpy = results.numpy()\n",
    "\n",
    "        img = ((res_numpy[0] + 1) * 127.5).astype(np.uint8)\n",
    "        frames.append(img)\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/volotat/DiffMorph/master/images/img_5.jpg\n",
      "229590/229590 [==============================] - 0s 0us/step\n",
      "Downloading data from https://raw.githubusercontent.com/volotat/DiffMorph/master/images/img_6.jpg\n",
      "221231/221231 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#source = tf.keras.utils.get_file(os.getcwd() + \"/img_1.jpg\", \n",
    "#                                 \"https://raw.githubusercontent.com/volotat/DiffMorph/master/images/img_1.jpg\")\n",
    "#target = tf.keras.utils.get_file(os.getcwd() + \"/img_2.jpg\", \n",
    "#                                 \"https://raw.githubusercontent.com/volotat/DiffMorph/master/images/img_2.jpg\")\n",
    "source = tf.keras.utils.get_file(os.getcwd() + \"/img_3.jpg\", \n",
    "                                 \"https://raw.githubusercontent.com/volotat/DiffMorph/master/images/img_3.jpg\")\n",
    "target = tf.keras.utils.get_file(os.getcwd() + \"/img_4.jpg\", \n",
    "                                 \"https://raw.githubusercontent.com/volotat/DiffMorph/master/images/img_4.jpg\")\n",
    "#source = tf.keras.utils.get_file(os.getcwd() + \"/img_5.jpg\", \n",
    "#                                 \"https://raw.githubusercontent.com/volotat/DiffMorph/master/images/img_5.jpg\")\n",
    "#target = tf.keras.utils.get_file(os.getcwd() + \"/img_6.jpg\", \n",
    "#                                 \"https://raw.githubusercontent.com/volotat/DiffMorph/master/images/img_6.jpg\")\n",
    "\n",
    "dom_a = cv2.imread(source, cv2.IMREAD_COLOR)\n",
    "dom_b = cv2.imread(target, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Checks if input and destination image are of the same dimensions.\n",
    "if (dom_a.shape[1] != dom_b.shape[1] or dom_a.shape[0] != dom_b.shape[0]):\n",
    "    print(\"Input Image is not the same dimensions as Destination Image.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Store original height and width\n",
    "ORIG_WIDTH = dom_a.shape[1]\n",
    "ORIG_HEIGHT = dom_a.shape[0]\n",
    "\n",
    "dom_a = cv2.cvtColor(dom_a, cv2.COLOR_BGR2RGB)\n",
    "dom_a = cv2.resize(dom_a, (im_sz, im_sz), interpolation = cv2.INTER_AREA)\n",
    "dom_a = dom_a / 127.5 - 1\n",
    "\n",
    "\n",
    "dom_b = cv2.cvtColor(dom_b, cv2.COLOR_BGR2RGB)\n",
    "dom_b = cv2.resize(dom_b, (im_sz, im_sz), interpolation = cv2.INTER_AREA)\n",
    "dom_b = dom_b / 127.5 - 1\n",
    "\n",
    "origins = dom_a.reshape(1, im_sz, im_sz, 3).astype(np.float32)\n",
    "targets = dom_b.reshape(1, im_sz, im_sz, 3).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train maps and generate frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 0.11399739235639572: 100%|██████████| 50/50 [01:07<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morphing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.74it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "preds = produce_warp_maps(origins, targets)\n",
    "\n",
    "steps = 100\n",
    "print(\"Morphing...\")\n",
    "frames = generate_frames(origins, targets, preds, steps)  # generate frames between source and target images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1478f19747a445cebcb4e30b666b2b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=50, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d465e82675e4096afdd916551063773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "import ipywidgets\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib import pyplot\n",
    "\n",
    "slider = ipywidgets.IntSlider(min=1, max=100, step=1)\n",
    "button_show = ipywidgets.Button(description=\"Show\")\n",
    "\n",
    "\n",
    "def on_click(_):\n",
    "    global slider\n",
    "    clear_output()\n",
    "    display(slider, button_show)\n",
    "    pyplot.imshow(frames[slider.value-1])\n",
    "\n",
    "\n",
    "button_show.on_click(on_click)\n",
    "slider.value = 50\n",
    "display(slider, button_show)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
